{
 "metadata": {
  "name": "",
  "signature": "sha256:10310e0d6a2db65405c9598a52cbc029da86f175c30faab9dd7840b3f24356de"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {
      "cellrole": "header"
     },
     "outputs": [
      {
       "html": [
        "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:5% !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "        color:#CD2305;\n",
        "    }\n",
        "    h3{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "        color:#CD2305;\n",
        "       }\n",
        "\th4{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "        color:#CD2305;\n",
        "       }\n",
        "    h5 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "        color:#CD2305;\n",
        "    }\t   \n",
        "    div.text_cell_render{\n",
        "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif; \n",
        "        /*font-family: 'Alegreya Sans', sans-serif;*/\n",
        "        font-size: 120%;\n",
        "        line-height: 120%;\n",
        "        width:55em;\n",
        "        margin-left:-10% !important;\n",
        "\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: 'Bitstream Vera Sans Mono','Lucida Console',monospace;\n",
        "\t\t\tfont-size: 90%;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h1 {\n",
        "        font-weight: 200;\n",
        "        font-size: 24pt;\n",
        "\t\tline-height: 100%;\n",
        "        color:#CD2305;\n",
        "        margin-bottom: 0.5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\t\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #CD2305;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x107b8cfd0>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure>\n",
      "<IMG SRC=\"../lectures/images/PhysicsLogo.jpg\" WIDTH=100 ALIGN=\"right\">\n",
      "</figure>\n",
      "# [Physics 411](http://jklymak.github.io/Phy411/) Time Series Analysis\n",
      "*Jody Klymak*\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Assignment 2"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Q1: Show that the correlation co-efficient is indeed related to the fraction of varaince explained by a linear dependence."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1** To start, make a $N(0,1)$ random variable $x$, with 200,000 entries.  Then make a linearly dependent variable $y_i= a x_i + n_i$, where a is some amplitude, and $n_i$ is a random noise varaible.  Assume that $n_i$ is distributed as $N(0,n)$, where $n$ is the noise level.\n",
      "\n",
      "Calculate the correlation co-efficient $r_{xy}$ between $x$ and $y$ for 40 different values of $n$, logarithmically spaced between 0.01 and 100. (hint use `np.logspace`).  \n",
      "\n",
      "Plot $r_{xy}$ versus the inverse of the noise $n$ normalized by the standard devaition of the signal $ax_i$: $\\frac{a s_x}{n}$   You may want to use `ax.loglog` to visualize the orders of magnitude.  \n",
      "\n",
      "Comment on the resulting comparison.\n",
      "<hr>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***COMMENT HERE***"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2** Repeat the above, but with a different value of $a$.  Comment on how (and why) $a$ changes the value of $r_{xy}$.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***COMMENT HERE***"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Q2: Monte Carlo on slopes and test versus student-t distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1** We stated without proof that the slope $b$ of a linear fit of $y$ to $x$ is distributed as a student-t distribution with $N-2$ degrees of freedom, with a standard devaition given by the standard deviation of $y$ around the fit model $\\tilde{y}$.   Lets test that emperically using a Monte Carlo technique.  \n",
      "\n",
      "First create an independet variable $x$ from 10 points from an $N(0,1)$ distribution.\n",
      "\n",
      "Next, using $n=1.0$, and $a=1.0$ create the dependent variables $y_i=a x_i + n_i$ where $n_i$ are drawn from the $N(0,n)$ distribution.  Calculate the slope $b$.  \n",
      "\n",
      "Do this 10000 times, and make a histogram of the resulting fits $b$.  Also histogram $s_{y|x}$ as defined in the notes.\n",
      "\n",
      "Comment on the histigrams\n",
      "\n",
      "<hr>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***COMMENT HERE***"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2** Assuming $s_{y|x}=1.$ (which is the same as our value of $n$), plot the student-t probability density function on the histogram of b and show that they compare favorably (if they don't you might need to check your work!)\n",
      "\n",
      "<hr>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3** Do the same procedure for a different number of data points, and a different value for the noise level $n$.  Remember to scale your theoretical histogram by the new expected value of $s_{y|x}$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Q3: Linear comparison of Deep Cove data to James Bay temperature data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the data:\n",
      "\n",
      "hourdata=np.genfromtxt('http://web.uvic.ca/~jklymak/Phy411/Data/AllHourly.txt')[[6,28],2:]\n",
      "dc = hourdata[0,:]\n",
      "jb=hourdata[1,:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1** Make a scatterplot of Plot James Bay versus Deep Cove."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2** Compute the linear Correlation Co-efficient."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3** Fit a straight line to the James Bay data as a fucntion of the Deep Cove data.  Comment on the fit.  (Do **NOT** use a canned routine for the fitting)\n",
      "\n",
      "<hr>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***COMMENT HERE***"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**4** Add the confidence intervals to your fit, and comment.  ***NO CANNED ROUTINES***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***COMMENT HERE***"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**5** Note that we have assumed that the Deep Cove data is independent and that the James Bay data is dependent.  There is no reason to assume this!  Do the fit in the other direction, and compare the slopes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***COMMENT HERE***"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NOTE** There is a way to treat both axes independently called \"Neutral Regression\".  It is relatively simple, and involves normalizing the total distance of each point from the trend line. <a href=\"http://journals.ametsoc.org/doi/pdf/10.1175/1520-0426(1999)016%3C0876%3AAPFANR%3E2.0.CO%3B2\">(Marsden 1999)</a>. This technique is strongly preferred if there is no reason to think that one data set is dependent on the other.  A caveat is that the data sets shoudl be normalized before fitting so that the \"distance\" has meaning.  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}